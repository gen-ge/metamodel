#!/usr/bin/env python3
"""
Context Navigator - Template Validator
Validador especializado que realiza valida√ß√µes profundas e espec√≠ficas
para cada tipo de template da metodologia Context Navigator.
"""

import os
import sys
import yaml
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass
from enum import Enum
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('template_validator')

class ValidationSeverity(Enum):
    """Severidade das valida√ß√µes"""
    ERROR = "error"
    WARNING = "warning"
    INFO = "info"
    SUCCESS = "success"

@dataclass
class ValidationResult:
    """Resultado de uma valida√ß√£o espec√≠fica"""
    rule_name: str
    severity: ValidationSeverity
    message: str
    line_number: Optional[int] = None
    suggestion: Optional[str] = None
    auto_fixable: bool = False

@dataclass
class TemplateValidationReport:
    """Relat√≥rio completo de valida√ß√£o de template"""
    template_type: str
    file_path: str
    overall_score: float
    results: List[ValidationResult]
    metadata_validation: Dict[str, Any]
    structure_validation: Dict[str, Any]
    content_validation: Dict[str, Any]
    completeness_score: float
    quality_score: float

class TemplateValidator:
    """Validador especializado para templates do Context Navigator"""
    
    def __init__(self, base_path: str = "."):
        """
        Inicializa o validador
        
        Args:
            base_path: Caminho base do projeto
        """
        self.base_path = Path(base_path)
        self.config = {}
        
        # Carregar configura√ß√£o
        self._load_config()
        
        # Inicializar regras de valida√ß√£o por template
        self._init_validation_rules()
        
    def _load_config(self) -> None:
        """Carrega configura√ß√£o do .contextrc"""
        config_file = self.base_path / ".contextrc"
        
        if not config_file.exists():
            logger.error(f"Arquivo .contextrc n√£o encontrado em {config_file}")
            return
            
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            logger.info("Configura√ß√£o carregada com sucesso")
        except Exception as e:
            logger.error(f"Erro ao carregar configura√ß√£o: {e}")
            
    def _init_validation_rules(self) -> None:
        """Inicializa regras de valida√ß√£o espec√≠ficas por template"""
        
        # Regras para template DECIS√ÉO
        self.decision_rules = {
            'required_sections': [
                'contexto e problema', 'an√°lise detalhada', 'op√ß√µes consideradas', 
                'decis√£o final', 'impactos e consequ√™ncias'
            ],
            'min_options': 2,
            'required_subsections': {
                'contexto e problema': ['situa√ß√£o atual', 'problema identificado', 'motiva√ß√£o'],
                'op√ß√µes consideradas': ['pr√≥s', 'contras', 'esfor√ßo', 'risco'],
                'decis√£o final': ['justificativa', 'fatores decisivos'],
                'impactos e consequ√™ncias': ['impactos positivos', 'impactos negativos']
            },
            'quality_indicators': ['trade-off', 'alternativa', 'justificativa', 'consequ√™ncia']
        }
        
        # Regras para template PROCESSO
        self.process_rules = {
            'required_sections': [
                'objetivo', 'pr√©-requisitos', 'procedimento principal', 
                'valida√ß√£o e testes', 'troubleshooting'
            ],
            'min_steps': 3,
            'required_subsections': {
                'pr√©-requisitos': ['conhecimentos necess√°rios', 'ferramentas obrigat√≥rias'],
                'procedimento principal': ['passo', 'valida√ß√£o', 'resultado esperado'],
                'troubleshooting': ['problemas comuns', 'sintomas', 'solu√ß√£o']
            },
            'quality_indicators': ['comando', 'verifica√ß√£o', 'teste', 'valida√ß√£o']
        }
        
        # Regras para template REFER√äNCIA
        self.reference_rules = {
            'required_sections': [
                'overview', 'configura√ß√£o e setup', 'refer√™ncia detalhada', 
                'exemplos pr√°ticos', 'versionamento'
            ],
            'min_examples': 2,
            'required_subsections': {
                'overview': ['prop√≥sito', 'escopo', 'audi√™ncia alvo'],
                'refer√™ncia detalhada': ['par√¢metros', 'resposta', 'c√≥digos de status'],
                'exemplos pr√°ticos': ['c√≥digo', 'resultado']
            },
            'quality_indicators': ['endpoint', 'par√¢metro', 'exemplo', 'response']
        }
        
        # Regras para template ARQUITETURA
        self.architecture_rules = {
            'required_sections': [
                'contexto arquitetural', 'vis√£o arquitetural', 'componentes arquiteturais',
                'fluxos arquiteturais', 'decis√µes arquiteturais'
            ],
            'min_components': 2,
            'required_subsections': {
                'contexto arquitetural': ['vis√£o geral', 'objetivos', 'restri√ß√µes'],
                'componentes arquiteturais': ['responsabilidade', 'interfaces', 'tecnologias'],
                'fluxos arquiteturais': ['sequ√™ncia', 'passos detalhados']
            },
            'quality_indicators': ['componente', 'fluxo', 'padr√£o', 'arquitetura']
        }
        
        # Regras para template AN√ÅLISE
        self.analysis_rules = {
            'required_sections': [
                'situa√ß√£o e contexto', 'metodologia e coleta de dados', 
                'dados e evid√™ncias', 'an√°lise detalhada', 'descobertas e insights',
                'a√ß√µes recomendadas'
            ],
            'min_findings': 2,
            'required_subsections': {
                'metodologia e coleta de dados': ['metodologia aplicada', 'fontes de dados'],
                'dados e evid√™ncias': ['dados quantitativos', 'dados qualitativos'],
                'an√°lise detalhada': ['root cause', 'correla√ß√£o'],
                'a√ß√µes recomendadas': ['a√ß√µes imediatas', 'prioridade', 'esfor√ßo']
            },
            'quality_indicators': ['m√©trica', 'evid√™ncia', 'correla√ß√£o', 'an√°lise']
        }
        
        # Regras para template PLANEJAMENTO
        self.planning_rules = {
            'required_sections': [
                'objetivos e vis√£o', 'escopo e entregas', 'cronograma e marcos',
                'recursos e equipe', 'riscos e depend√™ncias', 'm√©tricas e monitoramento'
            ],
            'min_milestones': 2,
            'required_subsections': {
                'objetivos e vis√£o': ['objetivos smart', 'resultados esperados'],
                'cronograma e marcos': ['marcos principais', 'fases do projeto'],
                'recursos e equipe': ['estrutura da equipe', 'or√ßamento detalhado'],
                'riscos e depend√™ncias': ['an√°lise de riscos', 'depend√™ncias cr√≠ticas']
            },
            'quality_indicators': ['objetivo', 'marco', 'cronograma', 'or√ßamento']
        }
        
    def _extract_sections(self, content: str) -> Dict[str, Dict[str, Any]]:
        """
        Extrai se√ß√µes e subse√ß√µes do documento
        
        Args:
            content: Conte√∫do do documento
            
        Returns:
            Dicion√°rio com estrutura das se√ß√µes
        """
        sections = {}
        current_section = None
        current_subsection = None
        
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            # Detectar headers
            if line.startswith('#'):
                level = len(line) - len(line.lstrip('#'))
                title = line.strip('#').strip().lower()
                
                if level == 2:  # Se√ß√£o principal
                    current_section = title
                    sections[current_section] = {
                        'line_number': i + 1,
                        'content': [],
                        'subsections': {},
                        'word_count': 0
                    }
                    current_subsection = None
                    
                elif level == 3 and current_section:  # Subse√ß√£o
                    current_subsection = title
                    sections[current_section]['subsections'][current_subsection] = {
                        'line_number': i + 1,
                        'content': [],
                        'word_count': 0
                    }
                    
            else:
                # Adicionar conte√∫do √† se√ß√£o/subse√ß√£o atual
                if current_section:
                    if current_subsection:
                        sections[current_section]['subsections'][current_subsection]['content'].append(line)
                        sections[current_section]['subsections'][current_subsection]['word_count'] += len(line.split())
                    else:
                        sections[current_section]['content'].append(line)
                        sections[current_section]['word_count'] += len(line.split())
                        
        return sections
        
    def _validate_metadata(self, metadata: Dict[str, Any], template_type: str) -> List[ValidationResult]:
        """
        Valida metadados espec√≠ficos do template
        
        Args:
            metadata: Metadados do documento
            template_type: Tipo do template
            
        Returns:
            Lista de resultados de valida√ß√£o
        """
        results = []
        
        # Validar campos obrigat√≥rios
        required_fields = self.config.get('metadata', {}).get('required_fields', {})
        
        for field, field_config in required_fields.items():
            if field not in metadata:
                results.append(ValidationResult(
                    rule_name=f"required_field_{field}",
                    severity=ValidationSeverity.ERROR,
                    message=f"Campo obrigat√≥rio '{field}' n√£o encontrado",
                    suggestion=f"Adicionar '{field}' aos metadados",
                    auto_fixable=True
                ))
                continue
                
            value = metadata[field]
            
            # Validar tipo de dado
            field_type = field_config.get('type', 'string')
            if field_type == 'string' and not isinstance(value, str):
                results.append(ValidationResult(
                    rule_name=f"field_type_{field}",
                    severity=ValidationSeverity.ERROR,
                    message=f"Campo '{field}' deve ser string, encontrado {type(value).__name__}",
                    suggestion=f"Converter '{field}' para string",
                    auto_fixable=True
                ))
                
            # Validar valores permitidos
            allowed_values = field_config.get('values', [])
            if allowed_values and value not in allowed_values:
                results.append(ValidationResult(
                    rule_name=f"field_value_{field}",
                    severity=ValidationSeverity.ERROR,
                    message=f"Campo '{field}' com valor inv√°lido '{value}'. Permitidos: {allowed_values}",
                    suggestion=f"Usar um dos valores permitidos: {', '.join(allowed_values)}",
                    auto_fixable=True
                ))
                
        # Validar consist√™ncia do doc_type
        if metadata.get('doc_type') != template_type:
            results.append(ValidationResult(
                rule_name="doc_type_consistency",
                severity=ValidationSeverity.ERROR,
                message=f"doc_type '{metadata.get('doc_type')}' inconsistente com template {template_type}",
                suggestion=f"Corrigir doc_type para '{template_type}'",
                auto_fixable=True
            ))
            
        # Validar formato de datas
        date_fields = ['created_date', 'last_updated']
        for date_field in date_fields:
            if date_field in metadata:
                try:
                    datetime.fromisoformat(str(metadata[date_field]))
                except ValueError:
                    results.append(ValidationResult(
                        rule_name=f"date_format_{date_field}",
                        severity=ValidationSeverity.ERROR,
                        message=f"Formato de data inv√°lido em '{date_field}': {metadata[date_field]}",
                        suggestion="Usar formato YYYY-MM-DD",
                        auto_fixable=True
                    ))
                    
        return results
        
    def _validate_structure(self, sections: Dict[str, Any], template_type: str) -> List[ValidationResult]:
        """
        Valida estrutura espec√≠fica do template
        
        Args:
            sections: Se√ß√µes extra√≠das do documento
            template_type: Tipo do template
            
        Returns:
            Lista de resultados de valida√ß√£o
        """
        results = []
        rules = getattr(self, f"{template_type}_rules", {})
        
        # Validar se√ß√µes obrigat√≥rias
        required_sections = rules.get('required_sections', [])
        found_sections = set(sections.keys())
        
        for required_section in required_sections:
            # Busca flex√≠vel (partial match)
            section_found = any(required_section in section_name for section_name in found_sections)
            
            if not section_found:
                results.append(ValidationResult(
                    rule_name=f"missing_section_{required_section}",
                    severity=ValidationSeverity.ERROR,
                    message=f"Se√ß√£o obrigat√≥ria n√£o encontrada: '{required_section}'",
                    suggestion=f"Adicionar se√ß√£o '## {required_section.title()}'",
                    auto_fixable=False
                ))
                
        # Validar subse√ß√µes obrigat√≥rias
        required_subsections = rules.get('required_subsections', {})
        
        for section_name, subsection_list in required_subsections.items():
            # Encontrar se√ß√£o correspondente
            matching_section = None
            for section_key in sections.keys():
                if section_name in section_key:
                    matching_section = section_key
                    break
                    
            if matching_section:
                section_subsections = set(sections[matching_section]['subsections'].keys())
                
                for required_subsection in subsection_list:
                    subsection_found = any(required_subsection in sub_name for sub_name in section_subsections)
                    
                    if not subsection_found:
                        results.append(ValidationResult(
                            rule_name=f"missing_subsection_{required_subsection}",
                            severity=ValidationSeverity.WARNING,
                            message=f"Subse√ß√£o recomendada n√£o encontrada em '{section_name}': '{required_subsection}'",
                            suggestion=f"Adicionar subse√ß√£o '### {required_subsection.title()}'",
                            line_number=sections[matching_section]['line_number'],
                            auto_fixable=False
                        ))
                        
        # Valida√ß√µes espec√≠ficas por tipo de template
        if template_type == 'decision':
            self._validate_decision_specific(sections, results)
        elif template_type == 'process':
            self._validate_process_specific(sections, results)
        elif template_type == 'reference':
            self._validate_reference_specific(sections, results)
        elif template_type == 'architecture':
            self._validate_architecture_specific(sections, results)
        elif template_type == 'analysis':
            self._validate_analysis_specific(sections, results)
        elif template_type == 'planning':
            self._validate_planning_specific(sections, results)
            
        return results
        
    def _validate_decision_specific(self, sections: Dict[str, Any], results: List[ValidationResult]) -> None:
        """Valida√ß√µes espec√≠ficas para template DECIS√ÉO"""
        
        # Verificar n√∫mero m√≠nimo de op√ß√µes
        options_section = None
        for section_name in sections.keys():
            if 'op√ß√µes consideradas' in section_name or 'op√ß√µes' in section_name:
                options_section = sections[section_name]
                break
                
        if options_section:
            content_text = '\n'.join(options_section['content'])
            option_count = len(re.findall(r'###.*op√ß√£o \d+', content_text, re.IGNORECASE))
            
            if option_count < self.decision_rules['min_options']:
                results.append(ValidationResult(
                    rule_name="min_options_decision",
                    severity=ValidationSeverity.WARNING,
                    message=f"Encontradas {option_count} op√ß√µes, recomendado m√≠nimo {self.decision_rules['min_options']}",
                    suggestion="Adicionar mais op√ß√µes para compara√ß√£o",
                    line_number=options_section['line_number']
                ))
                
        # Verificar presen√ßa de trade-offs
        all_content = ' '.join([
            ' '.join(section['content']) for section in sections.values()
        ])
        
        trade_off_indicators = ['trade-off', 'pr√≥s', 'contras', 'vantagem', 'desvantagem']
        trade_offs_found = sum(1 for indicator in trade_off_indicators if indicator in all_content.lower())
        
        if trade_offs_found < 2:
            results.append(ValidationResult(
                rule_name="trade_offs_analysis",
                severity=ValidationSeverity.WARNING,
                message="An√°lise de trade-offs parece insuficiente",
                suggestion="Detalhar pr√≥s/contras e trade-offs das op√ß√µes"
            ))
            
    def _validate_process_specific(self, sections: Dict[str, Any], results: List[ValidationResult]) -> None:
        """Valida√ß√µes espec√≠ficas para template PROCESSO"""
        
        # Verificar n√∫mero de passos
        procedure_section = None
        for section_name in sections.keys():
            if 'procedimento' in section_name or 'passos' in section_name:
                procedure_section = sections[section_name]
                break
                
        if procedure_section:
            content_text = '\n'.join(procedure_section['content'])
            step_count = len(re.findall(r'###.*passo \d+', content_text, re.IGNORECASE))
            
            if step_count < self.process_rules['min_steps']:
                results.append(ValidationResult(
                    rule_name="min_steps_process",
                    severity=ValidationSeverity.WARNING,
                    message=f"Encontrados {step_count} passos, recomendado m√≠nimo {self.process_rules['min_steps']}",
                    suggestion="Detalhar procedimento em mais passos espec√≠ficos",
                    line_number=procedure_section['line_number']
                ))
                
        # Verificar presen√ßa de comandos e valida√ß√µes
        all_content = ' '.join([
            ' '.join(section['content']) for section in sections.values()
        ])
        
        command_count = len(re.findall(r'```[^`]*```', all_content))
        validation_count = all_content.lower().count('valida√ß√£o') + all_content.lower().count('verificar')
        
        if command_count == 0:
            results.append(ValidationResult(
                rule_name="commands_present",
                severity=ValidationSeverity.WARNING,
                message="Nenhum bloco de comando encontrado",
                suggestion="Adicionar comandos espec√≠ficos usando blocos de c√≥digo ```"
            ))
            
        if validation_count < 2:
            results.append(ValidationResult(
                rule_name="validation_steps",
                severity=ValidationSeverity.WARNING,
                message="Poucos passos de valida√ß√£o encontrados",
                suggestion="Adicionar crit√©rios de valida√ß√£o para cada passo"
            ))
            
    def _validate_reference_specific(self, sections: Dict[str, Any], results: List[ValidationResult]) -> None:
        """Valida√ß√µes espec√≠ficas para template REFER√äNCIA"""
        
        # Verificar exemplos pr√°ticos
        examples_section = None
        for section_name in sections.keys():
            if 'exemplos' in section_name:
                examples_section = sections[section_name]
                break
                
        if examples_section:
            content_text = '\n'.join(examples_section['content'])
            example_count = len(re.findall(r'###.*exemplo \d+', content_text, re.IGNORECASE))
            
            if example_count < self.reference_rules['min_examples']:
                results.append(ValidationResult(
                    rule_name="min_examples_reference",
                    severity=ValidationSeverity.WARNING,
                    message=f"Encontrados {example_count} exemplos, recomendado m√≠nimo {self.reference_rules['min_examples']}",
                    suggestion="Adicionar mais exemplos pr√°ticos de uso",
                    line_number=examples_section['line_number']
                ))
                
        # Verificar endpoints e c√≥digos de resposta
        all_content = ' '.join([
            ' '.join(section['content']) for section in sections.values()
        ])
        
        endpoint_count = len(re.findall(r'(GET|POST|PUT|DELETE|PATCH)\s+/', all_content))
        status_code_count = len(re.findall(r'(200|201|400|401|404|500)', all_content))
        
        if endpoint_count == 0:
            results.append(ValidationResult(
                rule_name="api_endpoints",
                severity=ValidationSeverity.INFO,
                message="Nenhum endpoint de API encontrado",
                suggestion="Se aplic√°vel, documentar endpoints da API"
            ))
            
        if endpoint_count > 0 and status_code_count == 0:
            results.append(ValidationResult(
                rule_name="status_codes",
                severity=ValidationSeverity.WARNING,
                message="Endpoints encontrados mas sem c√≥digos de status",
                suggestion="Documentar c√≥digos de resposta HTTP"
            ))
            
    def _validate_architecture_specific(self, sections: Dict[str, Any], results: List[ValidationResult]) -> None:
        """Valida√ß√µes espec√≠ficas para template ARQUITETURA"""
        
        # Verificar componentes arquiteturais
        components_section = None
        for section_name in sections.keys():
            if 'componentes' in section_name:
                components_section = sections[section_name]
                break
                
        if components_section:
            content_text = '\n'.join(components_section['content'])
            component_count = len(re.findall(r'###.*componente \d+', content_text, re.IGNORECASE))
            
            if component_count < self.architecture_rules['min_components']:
                results.append(ValidationResult(
                    rule_name="min_components_architecture",
                    severity=ValidationSeverity.WARNING,
                    message=f"Encontrados {component_count} componentes, recomendado m√≠nimo {self.architecture_rules['min_components']}",
                    suggestion="Detalhar mais componentes da arquitetura",
                    line_number=components_section['line_number']
                ))
                
        # Verificar diagramas e fluxos
        all_content = ' '.join([
            ' '.join(section['content']) for section in sections.values()
        ])
        
        diagram_count = all_content.count('```') + all_content.count('‚îå') + all_content.count('‚îÇ')
        decision_count = all_content.lower().count('adr') + all_content.lower().count('decis√£o')
        
        if diagram_count == 0:
            results.append(ValidationResult(
                rule_name="architectural_diagrams",
                severity=ValidationSeverity.WARNING,
                message="Nenhum diagrama ou representa√ß√£o visual encontrada",
                suggestion="Adicionar diagramas ASCII ou refer√™ncias para diagramas"
            ))
            
    def _validate_analysis_specific(self, sections: Dict[str, Any], results: List[ValidationResult]) -> None:
        """Valida√ß√µes espec√≠ficas para template AN√ÅLISE"""
        
        # Verificar descobertas
        findings_section = None
        for section_name in sections.keys():
            if 'descobertas' in section_name or 'insights' in section_name:
                findings_section = sections[section_name]
                break
                
        if findings_section:
            content_text = '\n'.join(findings_section['content'])
            finding_count = len(re.findall(r'###.*descoberta \d+', content_text, re.IGNORECASE))
            
            if finding_count < self.analysis_rules['min_findings']:
                results.append(ValidationResult(
                    rule_name="min_findings_analysis",
                    severity=ValidationSeverity.WARNING,
                    message=f"Encontradas {finding_count} descobertas, recomendado m√≠nimo {self.analysis_rules['min_findings']}",
                    suggestion="Detalhar mais descobertas da an√°lise",
                    line_number=findings_section['line_number']
                ))
                
        # Verificar dados e m√©tricas
        all_content = ' '.join([
            ' '.join(section['content']) for section in sections.values()
        ])
        
        metric_count = len(re.findall(r'\d+(\.\d+)?%', all_content)) + len(re.findall(r'\d+ms', all_content))
        table_count = all_content.count('|')
        
        if metric_count == 0:
            results.append(ValidationResult(
                rule_name="quantitative_data",
                severity=ValidationSeverity.WARNING,
                message="Poucos dados quantitativos encontrados",
                suggestion="Incluir m√©tricas e dados num√©ricos na an√°lise"
            ))
            
        if table_count < 6:  # Pelo menos uma tabela pequena
            results.append(ValidationResult(
                rule_name="data_tables",
                severity=ValidationSeverity.INFO,
                message="Considerar usar tabelas para organizar dados",
                suggestion="Organizar dados em tabelas para melhor visualiza√ß√£o"
            ))
            
    def _validate_planning_specific(self, sections: Dict[str, Any], results: List[ValidationResult]) -> None:
        """Valida√ß√µes espec√≠ficas para template PLANEJAMENTO"""
        
        # Verificar marcos
        milestones_section = None
        for section_name in sections.keys():
            if 'marcos' in section_name or 'cronograma' in section_name:
                milestones_section = sections[section_name]
                break
                
        if milestones_section:
            content_text = '\n'.join(milestones_section['content'])
            milestone_count = content_text.lower().count('marco') + content_text.lower().count('m1') + content_text.lower().count('m2')
            
            if milestone_count < self.planning_rules['min_milestones']:
                results.append(ValidationResult(
                    rule_name="min_milestones_planning",
                    severity=ValidationSeverity.WARNING,
                    message=f"Encontrados {milestone_count} marcos, recomendado m√≠nimo {self.planning_rules['min_milestones']}",
                    suggestion="Definir marcos espec√≠ficos para o projeto",
                    line_number=milestones_section['line_number']
                ))
                
        # Verificar objetivos SMART
        objectives_section = None
        for section_name in sections.keys():
            if 'objetivos' in section_name:
                objectives_section = sections[section_name]
                break
                
        if objectives_section:
            content_text = '\n'.join(objectives_section['content'])
            smart_indicators = ['espec√≠fico', 'mensur√°vel', 'ating√≠vel', 'relevante', 'temporal']
            smart_count = sum(1 for indicator in smart_indicators if indicator in content_text.lower())
            
            if smart_count < 3:
                results.append(ValidationResult(
                    rule_name="smart_objectives",
                    severity=ValidationSeverity.WARNING,
                    message="Objetivos podem n√£o seguir crit√©rios SMART",
                    suggestion="Definir objetivos Espec√≠ficos, Mensur√°veis, Ating√≠veis, Relevantes e Temporais",
                    line_number=objectives_section['line_number']
                ))
                
    def _validate_content_quality(self, content: str, sections: Dict[str, Any], template_type: str) -> List[ValidationResult]:
        """
        Valida qualidade geral do conte√∫do
        
        Args:
            content: Conte√∫do completo
            sections: Se√ß√µes extra√≠das
            template_type: Tipo do template
            
        Returns:
            Lista de resultados de valida√ß√£o
        """
        results = []
        
        # Verificar comprimento adequado
        word_count = len(content.split())
        
        if word_count < 500:
            results.append(ValidationResult(
                rule_name="content_length",
                severity=ValidationSeverity.WARNING,
                message=f"Documento parece muito curto ({word_count} palavras)",
                suggestion="Expandir conte√∫do com mais detalhes e exemplos"
            ))
        elif word_count > 5000:
            results.append(ValidationResult(
                rule_name="content_length",
                severity=ValidationSeverity.INFO,
                message=f"Documento √© muito longo ({word_count} palavras)",
                suggestion="Considerar dividir em documentos menores"
            ))
            
        # Verificar presen√ßa de elementos estruturais
        checklist_count = content.count('- [ ]')
        table_count = content.count('|')
        code_block_count = content.count('```')
        
        if template_type in ['process', 'reference'] and code_block_count == 0:
            results.append(ValidationResult(
                rule_name="code_examples",
                severity=ValidationSeverity.WARNING,
                message="Nenhum exemplo de c√≥digo encontrado",
                suggestion="Adicionar exemplos pr√°ticos com c√≥digo"
            ))
            
        if template_type in ['decision', 'planning'] and checklist_count == 0:
            results.append(ValidationResult(
                rule_name="checklists",
                severity=ValidationSeverity.INFO,
                message="Considerar adicionar checklists",
                suggestion="Usar checklists para crit√©rios e valida√ß√µes"
            ))
            
        # Verificar links e refer√™ncias
        external_links = len(re.findall(r'https?://[^\s\]]+', content))
        internal_refs = len(re.findall(r'\[\[.*?\]\]', content))
        
        if external_links == 0 and internal_refs == 0:
            results.append(ValidationResult(
                rule_name="references",
                severity=ValidationSeverity.INFO,
                message="Nenhuma refer√™ncia externa ou interna encontrada",
                suggestion="Adicionar links para recursos e documentos relacionados"
            ))
            
        # Verificar se√ß√µes vazias
        empty_sections = []
        for section_name, section_data in sections.items():
            if section_data['word_count'] < 10:
                empty_sections.append(section_name)
                
        if empty_sections:
            results.append(ValidationResult(
                rule_name="empty_sections",
                severity=ValidationSeverity.WARNING,
                message=f"Se√ß√µes com pouco conte√∫do: {', '.join(empty_sections)}",
                suggestion="Expandir se√ß√µes com conte√∫do mais detalhado"
            ))
            
        return results
        
    def _calculate_scores(self, results: List[ValidationResult], sections: Dict[str, Any], template_type: str) -> Tuple[float, float, float]:
        """
        Calcula scores de completude, qualidade e geral
        
        Returns:
            Tupla com (completeness_score, quality_score, overall_score)
        """
        total_results = len(results)
        error_count = len([r for r in results if r.severity == ValidationSeverity.ERROR])
        warning_count = len([r for r in results if r.severity == ValidationSeverity.WARNING])
        
        # Score de completude (baseado em erros estruturais)
        completeness_score = max(0.0, 1.0 - (error_count * 0.2) - (warning_count * 0.1))
        
        # Score de qualidade (baseado em indicadores de qualidade)
        quality_indicators_found = 0
        rules = getattr(self, f"{template_type}_rules", {})
        quality_indicators = rules.get('quality_indicators', [])
        
        all_content = ' '.join([
            ' '.join(section['content']) for section in sections.values()
        ]).lower()
        
        for indicator in quality_indicators:
            if indicator in all_content:
                quality_indicators_found += 1
                
        quality_score = min(1.0, quality_indicators_found / len(quality_indicators)) if quality_indicators else 0.5
        
        # Score geral (m√©dia ponderada)
        overall_score = (completeness_score * 0.6) + (quality_score * 0.4)
        
        return completeness_score, quality_score, overall_score
        
    def validate_template(self, file_path: str) -> TemplateValidationReport:
        """
        Valida um template espec√≠fico
        
        Args:
            file_path: Caminho do arquivo a validar
            
        Returns:
            Relat√≥rio completo de valida√ß√£o
        """
        results = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return TemplateValidationReport(
                template_type='unknown',
                file_path=file_path,
                overall_score=0.0,
                results=[ValidationResult(
                    rule_name="file_read_error",
                    severity=ValidationSeverity.ERROR,
                    message=f"Erro ao ler arquivo: {e}",
                    suggestion="Verificar se arquivo existe e tem permiss√µes adequadas"
                )],
                metadata_validation={},
                structure_validation={},
                content_validation={},
                completeness_score=0.0,
                quality_score=0.0
            )
            
        # Extrair metadados
        metadata = {}
        if content.startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                try:
                    metadata = yaml.safe_load(parts[1]) or {}
                    content = parts[2]
                except yaml.YAMLError as e:
                    results.append(ValidationResult(
                        rule_name="metadata_parse_error",
                        severity=ValidationSeverity.ERROR,
                        message=f"Erro ao parsear metadados: {e}",
                        suggestion="Verificar sintaxe YAML dos metadados"
                    ))
                    
        template_type = metadata.get('doc_type', 'unknown')
        
        # Extrair se√ß√µes
        sections = self._extract_sections(content)
        
        # Executar valida√ß√µes
        metadata_results = self._validate_metadata(metadata, template_type)
        structure_results = self._validate_structure(sections, template_type)
        content_results = self._validate_content_quality(content, sections, template_type)
        
        results.extend(metadata_results)
        results.extend(structure_results)
        results.extend(content_results)
        
        # Calcular scores
        completeness_score, quality_score, overall_score = self._calculate_scores(results, sections, template_type)
        
        return TemplateValidationReport(
            template_type=template_type,
            file_path=file_path,
            overall_score=overall_score,
            results=results,
            metadata_validation={
                'total_rules': len(metadata_results),
                'errors': len([r for r in metadata_results if r.severity == ValidationSeverity.ERROR]),
                'warnings': len([r for r in metadata_results if r.severity == ValidationSeverity.WARNING])
            },
            structure_validation={
                'total_rules': len(structure_results),
                'errors': len([r for r in structure_results if r.severity == ValidationSeverity.ERROR]),
                'warnings': len([r for r in structure_results if r.severity == ValidationSeverity.WARNING])
            },
            content_validation={
                'total_rules': len(content_results),
                'errors': len([r for r in content_results if r.severity == ValidationSeverity.ERROR]),
                'warnings': len([r for r in content_results if r.severity == ValidationSeverity.WARNING])
            },
            completeness_score=completeness_score,
            quality_score=quality_score
        )
        
    def print_report(self, report: TemplateValidationReport) -> None:
        """Imprime relat√≥rio de valida√ß√£o formatado"""
        
        print(f"\n{'='*60}")
        print(f"TEMPLATE VALIDATOR - RELAT√ìRIO DE VALIDA√á√ÉO")
        print(f"{'='*60}")
        
        print(f"\nüìÑ ARQUIVO: {report.file_path}")
        print(f"üìã TIPO: {report.template_type.upper()}")
        print(f"‚≠ê SCORE GERAL: {report.overall_score:.2f}")
        print(f"üìä COMPLETUDE: {report.completeness_score:.2f}")
        print(f"üéØ QUALIDADE: {report.quality_score:.2f}")
        
        # Resumo por categoria
        print(f"\nüìà RESUMO POR CATEGORIA:")
        print(f"   Metadados: {report.metadata_validation['errors']} erros, {report.metadata_validation['warnings']} avisos")
        print(f"   Estrutura: {report.structure_validation['errors']} erros, {report.structure_validation['warnings']} avisos")
        print(f"   Conte√∫do: {report.content_validation['errors']} erros, {report.content_validation['warnings']} avisos")
        
        # Mostrar resultados por severidade
        errors = [r for r in report.results if r.severity == ValidationSeverity.ERROR]
        warnings = [r for r in report.results if r.severity == ValidationSeverity.WARNING]
        info = [r for r in report.results if r.severity == ValidationSeverity.INFO]
        
        if errors:
            print(f"\n‚ùå ERROS ({len(errors)}):")
            for error in errors:
                line_info = f" (linha {error.line_number})" if error.line_number else ""
                print(f"   ‚Ä¢ {error.message}{line_info}")
                if error.suggestion:
                    print(f"     üí° {error.suggestion}")
                    
        if warnings:
            print(f"\n‚ö†Ô∏è  AVISOS ({len(warnings)}):")
            for warning in warnings:
                line_info = f" (linha {warning.line_number})" if warning.line_number else ""
                print(f"   ‚Ä¢ {warning.message}{line_info}")
                if warning.suggestion:
                    print(f"     üí° {warning.suggestion}")
                    
        if info:
            print(f"\nüí° SUGEST√ïES ({len(info)}):")
            for suggestion in info[:5]:  # Mostrar s√≥ as primeiras 5
                print(f"   ‚Ä¢ {suggestion.message}")
                
        print(f"\n{'='*60}")

def main():
    """Fun√ß√£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Context Navigator Template Validator')
    parser.add_argument('--path', '-p', default='.', 
                       help='Caminho base do projeto')
    parser.add_argument('--file', '-f',
                       help='Validar arquivo espec√≠fico')
    parser.add_argument('--templates', '-t', action='store_true',
                       help='Validar todos os templates')
    parser.add_argument('--json', action='store_true',
                       help='Sa√≠da em formato JSON')
    
    args = parser.parse_args()
    
    validator = TemplateValidator(args.path)
    
    if args.file:
        file_path = Path(args.file)
        if file_path.exists():
            report = validator.validate_template(str(file_path))
            
            if args.json:
                # Converter para formato JSON serializ√°vel
                report_dict = {
                    'template_type': report.template_type,
                    'file_path': report.file_path,
                    'overall_score': report.overall_score,
                    'completeness_score': report.completeness_score,
                    'quality_score': report.quality_score,
                    'metadata_validation': report.metadata_validation,
                    'structure_validation': report.structure_validation,
                    'content_validation': report.content_validation,
                    'results': [
                        {
                            'rule_name': r.rule_name,
                            'severity': r.severity.value,
                            'message': r.message,
                            'line_number': r.line_number,
                            'suggestion': r.suggestion,
                            'auto_fixable': r.auto_fixable
                        }
                        for r in report.results
                    ]
                }
                print(json.dumps(report_dict, indent=2, ensure_ascii=False))
            else:
                validator.print_report(report)
        else:
            print(f"Arquivo n√£o encontrado: {file_path}")
            
    elif args.templates:
        templates_path = Path(args.path) / "templates"
        if templates_path.exists():
            for template_file in templates_path.glob("*.md"):
                print(f"\nüîç Validando: {template_file.name}")
                report = validator.validate_template(str(template_file))
                
                if args.json:
                    # S√≥ mostrar resumo em JSON para m√∫ltiplos arquivos
                    summary = {
                        'file': str(template_file),
                        'template_type': report.template_type,
                        'overall_score': report.overall_score,
                        'errors': len([r for r in report.results if r.severity == ValidationSeverity.ERROR]),
                        'warnings': len([r for r in report.results if r.severity == ValidationSeverity.WARNING])
                    }
                    print(json.dumps(summary, ensure_ascii=False))
                else:
                    validator.print_report(report)
        else:
            print(f"Pasta de templates n√£o encontrada: {templates_path}")
    else:
        print("Uso: python template_validator.py --file <arquivo> ou --templates")

if __name__ == '__main__':
    main() 